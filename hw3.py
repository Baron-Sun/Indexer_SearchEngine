import os
from lxml import etree
from bs4 import BeautifulSoup
from io import StringIO
import re,string
import json
import pickle
from nltk.stem import PorterStemmer

def tokenize(content):
    token = re.findall(r"[A-Za-z0-9]+", content.lower())
    return token

# Take 3 parameters: fileLocation, fileMap, invertedIndex
# fileLocation is the file location to extract data. We assume the file is in json
# fileMap is a global map to save the mapping data of url. (Key: uniqueDocumentId(generated by us), Value: url)
# invertedIndex is the global inverted index to save the data of each document, the format is:
    # key: token; value: {totalFreq: INT, 'docMap': { key: docId:INT; value: {rank: INT, positions:[INT]} } }
# Main Task: load the json data in "fileLocation" into invertedIndex and fileMap
def indexingFile(fileLocation, fileMap, invertedIndex):
    try:
        print('file location is: ', fileLocation)
        fileObj = open(fileLocation)
        wholeFile = json.loads(fileObj.read())
        url, content = wholeFile['url'], wholeFile['content'] # get url and content from the file
        fileObj.close()

        # Implement the fileMap and create docId
        uniqueDocId = -1
        if url not in fileMap.keys():
            uniqueDocId = len(fileMap)
            fileMap[url] = uniqueDocId
        else:
            uniqueDocId = fileMap[url]

        # Initialize rankDictionary with algorithm: totalRank of one token in one document = numTitle * 3 + numHead * 2 + b/strongNum * 1
        tagRankingDict = {'title': 5, 'h1': 4, 'h2': 3, 'h3': 2, 'b': 1, 'strong': 1, 'p': 0, 'span': 0, "li": 0, "a": 0, "cite": 0, "em": 0, "mark": 0, "b": 0, "abbr": 0}

        # Create a word dictionary to save all
        soup = BeautifulSoup(content, 'lxml')
        text = soup.find_all(text=True)
        pos = 0
        ps = PorterStemmer()
        for t in text:
            if t.parent.name in tagRankingDict.keys():
                rank = tagRankingDict[t.parent.name]
                for token in tokenize(t):
                    token = ps.stem(token) # using porter stemming
                    if(len(token) <= 3 or len(token) > 10):
                        continue
                    # if token not in invertedIndex, create an object
                    if token not in invertedIndex.keys():
                        invertedIndex[token] = {'totalFreq': 1, 'docDict': {uniqueDocId: {'rank': rank, 'positions': [pos]} } }
                    # if token was in invertedIndex, update it
                    else:
                        invertedIndex[token]['totalFreq'] += 1
                        # if document hasn't been stored in the same token, store it
                        if uniqueDocId not in invertedIndex[token]['docDict'].keys():
                            invertedIndex[token]['docDict'][uniqueDocId] = {'rank': rank, 'positions': [pos]}
                        # if document has been stored in the same token, update it
                        else:
                            invertedIndex[token]['docDict'][uniqueDocId]['rank'] += rank
                            invertedIndex[token]['docDict'][uniqueDocId]['positions'].append(pos)
                    pos += 1
    except ValueError as e:
        print("Error in File Location:", fileLocation)
        print(e)

# 1 paramter: folderLocation
# Main Task: explore all file in "folderLocation" with method indexingFile
def indexingInvertedTable(folderLocation):
    # Processing folder DEV
    invertedIndex = {} # key: token; value: {totalFreq: INT, docMap: { Key: docId:INT; value: {rank: INT, positions:[INT]} } }
    fileMap = {} # key: url of website, value: unique docId of each url
    with open('urlMap', 'rb') as f:
        fileMap = pickle.load(f) # get fileMap

    for (root, dirs, files) in os.walk('DEV/' + folderLocation):
        for filename in files:
            fileLocation = os.path.join(root, filename)
            try:
                # print('file_location is:', fileLocation)
                indexingFile(fileLocation, fileMap, invertedIndex)
            except ValueError as e:
                print("File Location:", fileLocation)
                print(e)

    # save the Inverted Table into disk            
    with open('./map_result/' + folderLocation , 'wb') as f:
        pickle.dump(invertedIndex, f)

    # save the url Map into disk     
    with open('urlMap', 'wb') as f:
        pickle.dump(fileMap, f)

if __name__ == '__main__':
    print("hello world")
    folderLocation1 = 'loading1'
    folderLocation2 = 'loading2'
    folderLocation3 = 'loading3'
    indexingInvertedTable(folderLocation3)
    
